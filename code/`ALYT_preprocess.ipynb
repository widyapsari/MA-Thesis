{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fbc8337-726f-4edd-a781-87312616282b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Widya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a49716-1eca-492e-94c0-c5c1b111a351",
   "metadata": {},
   "source": [
    "**Data for SVM**\n",
    "\n",
    "This following code prepared the dataset for machine learning. \n",
    "\n",
    "It creates the dataset with label ABU and NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd5310fc-43a4-4bfd-ba91-4df4ad5f614a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv( \"../data/ALYT_master.csv\")\n",
    "\n",
    "## drop unnecessary column and drop label 4 (uncertain) ##\n",
    "df = df.drop([\"comment_id\", \"label_normalised\", \"video_id\", \"video_topic\", \"video_type\"], axis=1)\n",
    "df = df[df['label'] != 4]\n",
    "\n",
    "## map class number to abuse/no abuse ##\n",
    "conditions = [\n",
    "    (df['label'] >= 1) & (df['label'] <= 3),\n",
    "    (df['label'] >= 5) & (df['label'] <= 7)\n",
    "]\n",
    "\n",
    "choices = ['NOT', 'ABU']\n",
    "\n",
    "# Create a new column 'label2' based on the conditions, keeping the original 'label' where conditions are not met\n",
    "df['label_class'] = np.select(conditions, choices, default=df['label'])\n",
    "df.to_csv(\"../data/alyt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb24aa58-b8b3-4edf-8cb4-fd8acc2770fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_comment(comment): \n",
    "    \"\"\"\n",
    "    This function is used to clean the sentence froom column \"comment\" dataframe alyt\n",
    "    :type comment: string\n",
    "    \"\"\"\n",
    "    comment = re.sub(r\"@[A-Za-z0-9]+\", '', comment)\n",
    "    comment = re.sub(\"#\", \"\", comment)\n",
    "    comment = re.sub(r\"[^a-zA-Z\\s]\", \"\", comment) #Removes also inner *, but also emoticones\n",
    "    comment = comment.lower()\n",
    "    \n",
    "#     # Remove stopwords\n",
    "#     stop_words = set(stopwords.words('english'))  \n",
    "#     words = tweet.split()\n",
    "#     words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "#     tweet = ' '.join(words)\n",
    "    return comment\n",
    "\n",
    "df_alyt = pd.read_csv(\"../data/alyt.csv\")\n",
    "df_alyt['comment'] = df_alyt['comment'].apply(clean_comment)\n",
    "index_to_drop = 11 #has no sentence (I- ... I- ..... I- .......????????????????????!)\n",
    "df_alyt = df_alyt.drop(index_to_drop)\n",
    "df_alyt.to_csv(\"../data/alyt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e88df62d-3676-4a33-81de-82e99a9b1388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## splitting the dataset into train and test. Ratio 70:30 ##\n",
    "df_alyt = pd.read_csv(\"../data/alyt.csv\")\n",
    "\n",
    "X = df_alyt [\"comment\"]\n",
    "y = df_alyt[\"label_class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify=y, random_state = 42) \n",
    "\n",
    "## save train data ##\n",
    "data_train = {\n",
    "    \"comment\" : X_train,\n",
    "    \"label\" : y_train}\n",
    "\n",
    "df = pd.DataFrame(data_train)\n",
    "df.to_csv(\"../data/ALYT_train.csv\", index = False)\n",
    "\n",
    "## save test data ##\n",
    "data_test = {\n",
    "    \"comment\" : X_test,\n",
    "    \"label\" : y_test}\n",
    "df = pd.DataFrame(data_test)\n",
    "df.to_csv(\"../data/ALYT_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0322eafd-8979-48e8-a477-64b8ce089a39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "NOT    11983\n",
      "ABU     1592\n",
      "Name: count, dtype: int64\n",
      "\n",
      "label\n",
      "NOT    5137\n",
      "ABU     682\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../data/ALYT_train.csv\")\n",
    "test = pd.read_csv(\"../data/ALYT_test.csv\")\n",
    "print(train.label.value_counts())\n",
    "print()\n",
    "print(test.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cffb244-15b2-4f41-bb32-007248967e99",
   "metadata": {},
   "source": [
    "**Data for BERT**\n",
    "\n",
    "This following codes prepare data for BERT \n",
    "\n",
    "it creates dataset with binary label (1 and 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ceb585b-01ad-4e24-ab2c-2c3bcc9224df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_train = train\n",
    "bert_train['label'] = bert_train['label'].replace({'NOT': 0, 'ABU': 1})\n",
    "bert_train.to_csv('../data/ALYT_train_bert.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c689ef93-5326-40af-bda3-b1871cd2804a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_test = test\n",
    "bert_test['label'] = bert_test['label'].replace({'NOT': 0, 'ABU': 1})\n",
    "bert_test.to_csv('../data/ALYT_test_bert.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
