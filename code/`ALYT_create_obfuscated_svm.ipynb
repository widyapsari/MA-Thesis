{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22fa7a8-00cb-40e4-a929-efbd9c13524d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bae9e1-eec6-48f3-aaad-bfc7fbdb3dcf",
   "metadata": {},
   "source": [
    "# 1. Interleave space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8ea1b4-e920-4999-bb30-ee329dd2f455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def interleave(word, char_to_interleave= ' '):\n",
    "    \"\"\"\n",
    "    This function modifies abusive words by interleaving char by space (default) or preferred symbol (\"_\")\n",
    "    \n",
    "    :type: word: abusive word on the df \n",
    "    :char_to_interleave: generate spaces in between the char of word, by default it will generate underscore (\"_\") \n",
    "    \n",
    "    return new_word: obfuscated word\n",
    "    \"\"\"\n",
    "    if len(word) == 1:\n",
    "        return word\n",
    "    new_word = word[0]\n",
    "    for char in word[1:]:\n",
    "        new_word = new_word + char_to_interleave + char\n",
    "    return new_word\n",
    "\n",
    "comment = pd.read_csv(\"../data/ALYT_test.csv\")\n",
    "keyword = pd.read_csv(\"../keyword/keyword_obfuscated.csv\")\n",
    "\n",
    "swearwords = sorted(set(keyword['word'].tolist()))\n",
    "\n",
    "def contains_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def return_sw(comment, lexicon):\n",
    "    sw = []\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            sw.append(l)\n",
    "    return sw\n",
    "\n",
    "def obfuscate_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            comment = comment.replace(l, interleave(l, \" \"))\n",
    "    return comment\n",
    "\n",
    "comment['found'] = comment['comment'].apply(lambda x: contains_swearwords(x, swearwords))\n",
    "comment['sw_found'] =comment['comment'].apply(lambda x: return_sw(x, swearwords))\n",
    "comment['obfuscated_comment'] = comment['comment'].apply(lambda x: obfuscate_swearwords(x, swearwords))\n",
    "comment = comment[['comment', 'obfuscated_comment', 'found', 'sw_found', 'label']]\n",
    "comment.to_csv('../data/alyt_obf/ALYT_OBF_1interleave.csv', index=False)\n",
    "\n",
    "comment['label'] = comment['label'].replace({'NOT': 0, 'ABU': 1})\n",
    "comment.to_csv('../data/alyt_obf_bert/ALYT_OBF_bert_1interleave.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd74262c-9021-4b95-b16e-c7f4ea983e28",
   "metadata": {},
   "source": [
    "# 2 Swap Two Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0658d053-4781-48b6-ab3c-1690acd8d253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def swap(word):\n",
    "    \"\"\"\n",
    "    this code will modify the word in df by swapping the first and the second character of word\n",
    "    :type: word:abusive word on the df \n",
    "\n",
    "    \"\"\"\n",
    "    if len(word) < 2:\n",
    "        return word \n",
    "    else:\n",
    "        return word[1] + word[0] + word[2:]\n",
    "    \n",
    "comment = pd.read_csv(\"../data/ALYT_test.csv\")\n",
    "keyword = pd.read_csv(\"../keyword/keyword_obfuscated.csv\")\n",
    "\n",
    "swearwords = sorted(set(keyword['word'].tolist()))\n",
    "\n",
    "def contains_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def return_sw(comment, lexicon):\n",
    "    sw = []\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            sw.append(l)\n",
    "    return sw\n",
    "\n",
    "def obfuscate_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            comment = comment.replace(l, swap(l))\n",
    "    return comment\n",
    "\n",
    "comment['found'] = comment['comment'].apply(lambda x: contains_swearwords(x, swearwords))\n",
    "comment['sw_found'] =comment['comment'].apply(lambda x: return_sw(x, swearwords))\n",
    "comment['obfuscated_comment'] = comment['comment'].apply(lambda x: obfuscate_swearwords(x, swearwords))\n",
    "comment = comment[['comment', 'obfuscated_comment', 'found', 'sw_found', 'label']]\n",
    "comment.to_csv('../data/alyt_obf/ALYT_OBF_2swapchar.csv', index=False)\n",
    "\n",
    "# save dataset for BERT, label 1 or 0)\n",
    "comment['label'] = comment['label'].replace({'NOT': 0, 'ABU': 1})\n",
    "comment.to_csv('../data/alyt_obf_bert/ALYT_OBF_bert_2swapchar.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac470648-6be0-4a67-ad65-8e5de220b777",
   "metadata": {},
   "source": [
    "# 3. replace o with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4300aff-a6e3-42ef-bb62-206ebe0af86e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def obfuscate_char(word, char_to_replace, new_char):\n",
    "    \"\"\"\n",
    "    This function obfuscates the word by replacing first vowel of abusive words with asterisk \n",
    "    \n",
    "    :type: word: abusive word on the df \n",
    "    :char_to_replace: replace the first found vowel in the word\n",
    "    :new_char: the replaced character, in this case first vowel -> *, o -> 0 \n",
    "    \n",
    "    return new_word: obfuscated word\n",
    "    \"\"\"\n",
    "    \n",
    "    first_char_found = False\n",
    "    new_word = \"\"\n",
    "\n",
    "    for char in word:\n",
    "        if not first_char_found and char in char_to_replace:\n",
    "            new_word += new_char\n",
    "            first_char_found = True\n",
    "        else:\n",
    "            new_word += char\n",
    "\n",
    "    return new_word\n",
    "\n",
    "comment = pd.read_csv(\"../data/ALYT_test.csv\")\n",
    "keyword = pd.read_csv(\"../keyword/keyword_obfuscated.csv\")\n",
    "\n",
    "swearwords = sorted(set(keyword['word'].tolist()))\n",
    "\n",
    "def contains_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def return_sw(comment, lexicon):\n",
    "    sw = []\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            sw.append(l)\n",
    "    return sw\n",
    "\n",
    "def obfuscate_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            comment = comment.replace(l, obfuscate_char(l,\"o\",'0'))\n",
    "    return comment\n",
    "\n",
    "comment['found'] = comment['comment'].apply(lambda x: contains_swearwords(x, swearwords))\n",
    "comment['sw_found'] =comment['comment'].apply(lambda x: return_sw(x, swearwords))\n",
    "comment['obfuscated_comment'] = comment['comment'].apply(lambda x: obfuscate_swearwords(x, swearwords))\n",
    "comment = comment[['comment', 'obfuscated_comment', 'found', 'sw_found', 'label']]\n",
    "comment.to_csv('../data/alyt_obf/ALYT_OBF_3replace_o.csv', index=False)\n",
    "\n",
    "comment['label'] = comment['label'].replace({'NOT': 0, 'ABU': 1})\n",
    "comment.to_csv('../data/alyt_obf_bert/ALYT_OBF_bert_3replace_o.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf5911-037b-4309-a02d-daaba8cf74ea",
   "metadata": {},
   "source": [
    "# 4. Ommit Char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55676f79-2c05-4e32-92a5-f72a2a556665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ommit_char(word, char_to_replace, new_char):\n",
    "    \"\"\"\n",
    "    This function obfuscates the word ommiting all vowels in abusive words\n",
    "     \n",
    "    :type: word: abusive word on the df \n",
    "    :char_to_replace: replace the first found vowel in the word\n",
    "    :new_char: the replaced character, in this case all vowel will be replaced by empty space (\"\") \n",
    "    \n",
    "    return new_word: obfuscated word\n",
    "    \"\"\"\n",
    "        \n",
    "    new_word = \"\"    \n",
    "    for char in word:\n",
    "        if char not in char_to_replace:\n",
    "            new_word += char\n",
    "    return new_word\n",
    "\n",
    "comment = pd.read_csv(\"../data/ALYT_test.csv\")\n",
    "keyword = pd.read_csv(\"../keyword/keyword_obfuscated.csv\")\n",
    "\n",
    "swearwords = sorted(set(keyword['word'].tolist()))\n",
    "\n",
    "def contains_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def return_sw(comment, lexicon):\n",
    "    sw = []\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            sw.append(l)\n",
    "    return sw\n",
    "\n",
    "def obfuscate_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            comment = comment.replace(l, ommit_char(l,\"aiueo\",''))\n",
    "    return comment\n",
    "\n",
    "comment['found'] = comment['comment'].apply(lambda x: contains_swearwords(x, swearwords))\n",
    "comment['sw_found'] =comment['comment'].apply(lambda x: return_sw(x, swearwords))\n",
    "comment['obfuscated_comment'] = comment['comment'].apply(lambda x: obfuscate_swearwords(x, swearwords))\n",
    "comment = comment[['comment', 'obfuscated_comment', 'found', 'sw_found', 'label']]\n",
    "comment.to_csv('../data/alyt_obf/ALYT_OBF_4ommit_char.csv', index=False)\n",
    "\n",
    "comment['label'] = comment['label'].replace({'NOT': 0, 'ABU': 1})\n",
    "comment.to_csv('../data/alyt_obf_bert/ALYT_OBF_bert_4ommit_char.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c7ce13-e9ea-419b-a8c1-20152e0da808",
   "metadata": {},
   "source": [
    "# 5. Extra Char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12b10d54-38de-43df-816b-41b769b3c010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extra_char(word):\n",
    "    \"\"\"\n",
    "    This function will modify the word by adding random ascii character, specified on alphabet\n",
    "    \n",
    "    :type: word: abusive word on df\n",
    "    \"\"\"\n",
    "    import random\n",
    "    random_ascii_character = chr(random.randint(97, 122))\n",
    "    return word + random_ascii_character\n",
    "\n",
    "comment = pd.read_csv(\"../data/ALYT_test.csv\")\n",
    "keyword = pd.read_csv(\"../keyword/keyword_obfuscated.csv\")\n",
    "\n",
    "swearwords = sorted(set(keyword['word'].tolist()))\n",
    "\n",
    "def contains_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def return_sw(comment, lexicon):\n",
    "    sw = []\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            sw.append(l)\n",
    "    return sw\n",
    "\n",
    "def obfuscate_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            comment = comment.replace(l, extra_char(l))\n",
    "    return comment\n",
    "\n",
    "comment['found'] = comment['comment'].apply(lambda x: contains_swearwords(x, swearwords))\n",
    "comment['sw_found'] =comment['comment'].apply(lambda x: return_sw(x, swearwords))\n",
    "comment['obfuscated_comment'] = comment['comment'].apply(lambda x: obfuscate_swearwords(x, swearwords))\n",
    "comment = comment[['comment', 'obfuscated_comment', 'found', 'sw_found', 'label']]\n",
    "comment.to_csv('../data/alyt_obf/ALYT_OBF_5extra_char.csv', index=False)\n",
    "\n",
    "comment['label'] = comment['label'].replace({'NOT': 0, 'ABU': 1})\n",
    "comment.to_csv('../data/alyt_obf_bert/ALYT_OBF_bert_5extra_char.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e2f58-46aa-4c22-99cd-be70791c5389",
   "metadata": {},
   "source": [
    "# 6. Replace First vowel to asterisks (*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41e46b90-3689-4497-930c-870c8bb8b965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def obfuscate_char(word, char_to_replace, new_char):\n",
    "    \"\"\"\n",
    "    This function obfuscates the word by replacing first vowel of abusive words with asterisk \n",
    "    \n",
    "    :type: word: abusive word on the df \n",
    "    :char_to_replace: replace the first found vowel in the word\n",
    "    :new_char: the replaced character, in this case first vowel -> *, o -> 0 \n",
    "    \n",
    "    return new_word: obfuscated word\n",
    "    \"\"\"\n",
    "    \n",
    "    first_char_found = False\n",
    "    new_word = \"\"\n",
    "\n",
    "    for char in word:\n",
    "        if not first_char_found and char in char_to_replace:\n",
    "            new_word += new_char\n",
    "            first_char_found = True\n",
    "        else:\n",
    "            new_word += char\n",
    "\n",
    "    return new_word\n",
    "\n",
    "comment = pd.read_csv(\"../data/ALYT_test.csv\")\n",
    "keyword = pd.read_csv(\"../keyword/keyword_obfuscated.csv\")\n",
    "\n",
    "swearwords = sorted(set(keyword['word'].tolist()))\n",
    "\n",
    "def contains_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def return_sw(comment, lexicon):\n",
    "    sw = []\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            sw.append(l)\n",
    "    return sw\n",
    "\n",
    "def obfuscate_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            comment = comment.replace(l, obfuscate_char(l,\"aiueo\",'*'))\n",
    "    return comment\n",
    "\n",
    "comment['found'] = comment['comment'].apply(lambda x: contains_swearwords(x, swearwords))\n",
    "comment['sw_found'] =comment['comment'].apply(lambda x: return_sw(x, swearwords))\n",
    "comment['obfuscated_comment'] = comment['comment'].apply(lambda x: obfuscate_swearwords(x, swearwords))\n",
    "comment = comment[['comment', 'obfuscated_comment', 'found', 'sw_found', 'label']]\n",
    "comment.to_csv('../data/alyt_obf/ALYT_OBF_6to_asterisks.csv', index=False)\n",
    "\n",
    "comment['label'] = comment['label'].replace({'NOT': 0, 'ABU': 1})\n",
    "comment.to_csv('../data/alyt_obf_bert/ALYT_OBF_bert_6to_asterisks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb4a1dd-8c04-4914-8a71-c0c53d99f4f7",
   "metadata": {},
   "source": [
    "# 7. Duplicate first vowel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96cbedc7-e2f6-47c0-8e31-608971e5041e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def duplicate_char(word, char_to_duplicate):\n",
    "    \"\"\"\n",
    "    This function will modify the word by adding extra character of first found vowel\n",
    "    \n",
    "    :type: word: abusive word on df\n",
    "    :type: char_to_duplicate ('aiueo')\n",
    "    \n",
    "    return new_word: obfuscated word\n",
    "    \"\"\"\n",
    "    first_char_found = False\n",
    "    new_word = \"\"\n",
    "\n",
    "    for char in word:\n",
    "        if not first_char_found and char in char_to_duplicate:\n",
    "            new_word += char * 5\n",
    "            first_char_found = True\n",
    "        else:\n",
    "            new_word += char\n",
    "\n",
    "    return new_word\n",
    "\n",
    "comment = pd.read_csv(\"../data/ALYT_test.csv\")\n",
    "keyword = pd.read_csv(\"../keyword/keyword_obfuscated.csv\")\n",
    "\n",
    "swearwords = sorted(set(keyword['word'].tolist()))\n",
    "\n",
    "def contains_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def return_sw(comment, lexicon):\n",
    "    sw = []\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            sw.append(l)\n",
    "    return sw\n",
    "\n",
    "def obfuscate_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            comment = comment.replace(l, duplicate_char(l, \"aiueo\"))\n",
    "    return comment\n",
    "\n",
    "comment['found'] = comment['comment'].apply(lambda x: contains_swearwords(x, swearwords))\n",
    "comment['sw_found'] =comment['comment'].apply(lambda x: return_sw(x, swearwords))\n",
    "comment['obfuscated_comment'] = comment['comment'].apply(lambda x: obfuscate_swearwords(x, swearwords))\n",
    "comment = comment[['comment', 'obfuscated_comment', 'found', 'sw_found', 'label']]\n",
    "comment.to_csv('../data/alyt_obf/ALYT_OBF_7duplicate_char.csv', index=False)\n",
    "\n",
    "comment['label'] = comment['label'].replace({'NOT': 0, 'ABU': 1})\n",
    "comment.to_csv('../data/alyt_obf_bert/ALYT_OBF_bert_7duplicate_char.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af37bc5-536b-407e-a94c-578bc59e459a",
   "metadata": {},
   "source": [
    "# 8. Random Obfuscation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9e183a-5801-4ac1-ad77-064121387c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_obfuscation(word):\n",
    "    \"\"\"\n",
    "    This function will modify the word by with all the method above.\n",
    "    \n",
    "    :type: word: abusive word on df\n",
    "    \"\"\"\n",
    "\n",
    "    import random\n",
    "    method = random.randint(0,7)\n",
    "    if method == 0:\n",
    "        return obfuscate_char(word, \"aeiou\", '*')\n",
    "    if method == 1:\n",
    "        return obfuscate_char(word, \"o\", \"0\")\n",
    "    if method == 2:\n",
    "        return ommit_char(word, \"aiueo\", \"\")\n",
    "    if method == 3:\n",
    "        return interleave(word, \" \")\n",
    "    if method == 4:\n",
    "        return interleave(word, \"_\")\n",
    "    if method == 5:\n",
    "        return swap(word)\n",
    "    if method == 6:\n",
    "        return duplicate_char(word, \"aeiou\")\n",
    "    if method == 7:\n",
    "        return extra_char(word)\n",
    "    \n",
    "comment = pd.read_csv(\"../data/ALYT_test.csv\")\n",
    "keyword = pd.read_csv(\"../keyword/keyword_obfuscated.csv\")\n",
    "\n",
    "swearwords = sorted(set(keyword['word'].tolist()))\n",
    "\n",
    "def contains_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def return_sw(comment, lexicon):\n",
    "    sw = []\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            sw.append(l)\n",
    "    return sw\n",
    "\n",
    "def obfuscate_swearwords(comment, lexicon):\n",
    "    clean_comment = set(word_tokenize(comment))\n",
    "    for l in lexicon:\n",
    "        if l in clean_comment:\n",
    "            comment = comment.replace(l, random_obfuscation(l))\n",
    "    return comment\n",
    "\n",
    "comment['found'] = comment['comment'].apply(lambda x: contains_swearwords(x, swearwords))\n",
    "comment['sw_found'] =comment['comment'].apply(lambda x: return_sw(x, swearwords))\n",
    "comment['obfuscated_comment'] = comment['comment'].apply(lambda x: obfuscate_swearwords(x, swearwords))\n",
    "comment = comment[['comment', 'obfuscated_comment', 'found', 'sw_found', 'label']]\n",
    "comment.to_csv('../data/alyt_obf/ALYT_OBF_8random_obf.csv', index=False)\n",
    "\n",
    "comment['label'] = comment['label'].replace({'NOT': 0, 'ABU': 1})\n",
    "comment.to_csv('../data/alyt_obf_bert/ALYT_OBF_bert_8random_obf.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
